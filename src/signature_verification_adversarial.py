# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PkmFmONni69H041tQiuRz2KajyN8e1rC
"""

import zipfile
import os
import numpy as np
import cv2
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, roc_auc_score
from tensorflow.keras.callbacks import ModelCheckpoint

# 1. UNZIP YOUR UPLOADED DATASET
zip_file_path = '/content/signatures.zip'  # Change if different!
extract_dir = 'SignatureDataset'

print("Extracting zip file...")
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_dir)

dataset_dir = 'SignatureDataset/signatures'

print("Extracted folders:", os.listdir(dataset_dir))
print("Genuine examples:", os.listdir(os.path.join(dataset_dir, 'Genuine'))[:3])
print("Forgery examples:", os.listdir(os.path.join(dataset_dir, 'Forgery'))[:3])

# 2. IMAGE PREPROCESSING FUNCTION
def preprocess_signature_image(image_path):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    image = cv2.resize(image, (224, 224))  # For ResNet50 input size
    _, thresh_img = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    inverted = cv2.bitwise_not(thresh_img)
    # Convert to 3 channels
    img_3ch = cv2.cvtColor(inverted, cv2.COLOR_GRAY2RGB)
    return img_3ch

# 3. LOAD DATASET IMAGES AND LABELS
def load_dataset(dataset_dir):
    X = []
    y = []
    for label_name, label_value in [('Genuine', 1), ('Forgery', 0)]:
        folder_path = os.path.join(dataset_dir, label_name)
        if not os.path.exists(folder_path):
            print(f"Warning: folder not found: {folder_path}")
            continue
        for filename in os.listdir(folder_path):
            if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):
                img_path = os.path.join(folder_path, filename)
                img = preprocess_signature_image(img_path)
                X.append(img)
                y.append(label_value)
    return np.array(X), np.array(y)

# 4. LOAD AND PREPROCESS DATA
print("\nLoading and preprocessing dataset...")
X, y = load_dataset(dataset_dir)
print(f"Loaded {len(X)} samples.")

# Normalize using preprocess_input from ResNet50
X = preprocess_input(X.astype(np.float32))

# Split dataset
print("\nSplitting into train/test...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42)

# 5. DEFINE CNN MODEL BASED ON ResNet50
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.5)(x)
predictions = Dense(1, activation='sigmoid')(x)
model = Model(inputs=base_model.input, outputs=predictions)

# Freeze base model layers first
for layer in base_model.layers:
    layer.trainable = False

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Define checkpoint callback to save best model during initial training (new Keras format)
checkpoint_path = 'best_model_initial.keras'
checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=1,
                             save_best_only=True, mode='max')

print("\nTraining CNN model...")
history = model.fit(
    X_train, y_train,
    validation_split=0.2,
    epochs=5,
    batch_size=32,
    verbose=2,
    callbacks=[checkpoint]
)

# Load the best weights from initial training
model.load_weights(checkpoint_path)

# Optionally, unfreeze some layers and fine-tune further
for layer in base_model.layers[-20:]:
    layer.trainable = True
model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='binary_crossentropy', metrics=['accuracy'])

# Define checkpoint callback for fine-tuning phase (new Keras format)
fine_tune_checkpoint_path = 'best_model_finetuned.keras'
fine_tune_checkpoint = ModelCheckpoint(fine_tune_checkpoint_path, monitor='val_accuracy', verbose=1,
                                       save_best_only=True, mode='max')

print("\nFine-tuning CNN model...")
history_fine = model.fit(
    X_train, y_train,
    validation_split=0.2,
    epochs=5,
    batch_size=32,
    verbose=2,
    callbacks=[fine_tune_checkpoint]
)

# Load the best weights from fine-tuning
model.load_weights(fine_tune_checkpoint_path)

# 7. EVALUATE MODEL ON TEST SET
print("\nEvaluating model on test set:")
y_pred_proba = model.predict(X_test).flatten()
y_pred = (y_pred_proba > 0.5).astype(int)

print(classification_report(y_test, y_pred))
print("ROC-AUC Score:", roc_auc_score(y_test, y_pred_proba))

import tensorflow as tf
import numpy as np
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from sklearn.metrics import classification_report, roc_auc_score
import matplotlib.pyplot as plt

# 1. Build your model exactly as during training/fine-tuning
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.5)(x)
predictions = Dense(1, activation='sigmoid')(x)
model = Model(inputs=base_model.input, outputs=predictions)

# 2. Load best fine-tuned weights
model.load_weights('best_model_finetuned.keras')

# 3. Shape-correct FGSM batch implementation
def fgsm_attack_batch(model, images, labels, epsilon=0.01, batch_size=1):
    adv_images = []
    for start in range(0, len(images), batch_size):
        end = min(start + batch_size, len(images))
        img_batch = tf.convert_to_tensor(images[start:end])
        lbl_batch = tf.convert_to_tensor(labels[start:end], dtype=tf.float32)
        lbl_batch = tf.reshape(lbl_batch, (-1, 1))  # Guarantee (batch_size, 1)
        with tf.GradientTape() as tape:
            tape.watch(img_batch)
            pred = model(img_batch)
            pred = tf.reshape(pred, (-1, 1))         # Guarantee (batch_size, 1)
            loss = tf.keras.losses.binary_crossentropy(lbl_batch, pred)
        grad = tape.gradient(loss, img_batch)
        adv = img_batch + epsilon * tf.sign(grad)
        adv = tf.clip_by_value(adv, -1.0, 1.0)
        adv_images.append(adv.numpy())
    return np.concatenate(adv_images, axis=0)

# 4. Test on a small batch for safety
NUM_SAMPLES = 20  # Start small for memory safety
X_test_small = X_test[:NUM_SAMPLES]
y_test_small = y_test[:NUM_SAMPLES]
epsilon_val = 0.01
X_test_adv = fgsm_attack_batch(model, X_test_small, y_test_small, epsilon=epsilon_val, batch_size=1)

# 5. Evaluate
y_pred_adv_proba = model.predict(X_test_adv, batch_size=1).flatten()
y_pred_adv = (y_pred_adv_proba > 0.5).astype(int)
print("Evaluation on adversarial examples (FGSM, epsilon = %s):" % epsilon_val)
print(classification_report(y_test_small, y_pred_adv))
print("ROC-AUC Score on adversarial examples:", roc_auc_score(y_test_small, y_pred_adv_proba))

# 6. Visualize
def visualize_adversarial(original, adversarial, n=5):
    plt.figure(figsize=(12, 4))
    for i in range(n):
        plt.subplot(2, n, i + 1)
        plt.imshow((original[i] + 1) / 2)
        plt.title("Original")
        plt.axis('off')
        plt.subplot(2, n, i + 1 + n)
        plt.imshow((adversarial[i] + 1) / 2)
        plt.title("Adversarial")
        plt.axis('off')
    plt.show()

visualize_adversarial(X_test_small, X_test_adv, n=min(5, NUM_SAMPLES))

# Now you can safely scale up NUM_SAMPLES or batch size if successful!

import tensorflow as tf
import numpy as np

# Use a small subset for demonstration (first 10 samples)
X_train_small = X_train[:5]
y_train_small = y_train[:5]

def generate_adversarial_examples(model, images, labels, epsilon=0.01):
    images = tf.convert_to_tensor(images)
    labels = tf.convert_to_tensor(labels, dtype=tf.float32)
    labels = tf.reshape(labels, (-1, 1))
    with tf.GradientTape() as tape:
        tape.watch(images)
        predictions = model(images)
        loss = tf.keras.losses.binary_crossentropy(labels, predictions)
    grads = tape.gradient(loss, images)
    adv_images = images + epsilon * tf.sign(grads)
    adv_images = tf.clip_by_value(adv_images, -1.0, 1.0)
    return adv_images.numpy()

# Compile the model if not compiled
model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy'])

epochs = 1             # For demo; increase if desired
batch_size = 1         # Smallest, safest size
epsilon = 0.01         # Perturbation

for epoch in range(epochs):
    print(f"Adversarial Training Epoch {epoch+1}/{epochs}")
    # Shuffle only the small set
    idx = np.random.permutation(len(X_train_small))
    X_train_shuffled = X_train_small[idx]
    y_train_shuffled = y_train_small[idx]
    for start in range(0, len(X_train_small), batch_size):
        end = min(start + batch_size, len(X_train_small))
        clean_images = X_train_shuffled[start:end]
        labels = y_train_shuffled[start:end]
        adv_images = generate_adversarial_examples(model, clean_images, labels, epsilon)
        X_combined = np.concatenate([clean_images, adv_images])
        y_combined = np.concatenate([labels, labels])
        model.train_on_batch(X_combined, y_combined)

# Save your robust (adversarially trained) model weights
model.save_weights('robust_model_adversarial_trained_demo.weights.h5')
print("Robust model weights (demo) saved as 'robust_model_adversarial_trained_demo.weights.h5'")

# 1. Rebuild the SAME model architecture as always
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.5)(x)
predictions = Dense(1, activation='sigmoid')(x)
robust_model = Model(inputs=base_model.input, outputs=predictions)

# 2. Load the robust model weights
robust_model.load_weights('robust_model_adversarial_trained_demo.weights.h5')

# 3. Compile for evaluation
robust_model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy'])

# 4. Generate adversarial test examples using the new robust model
def fgsm_attack_batch(model, images, labels, epsilon=0.01, batch_size=1):
    adv_images = []
    for start in range(0, len(images), batch_size):
        end = min(start + batch_size, len(images))
        img_batch = tf.convert_to_tensor(images[start:end])
        lbl_batch = tf.convert_to_tensor(labels[start:end], dtype=tf.float32)
        lbl_batch = tf.reshape(lbl_batch, (-1, 1))
        with tf.GradientTape() as tape:
            tape.watch(img_batch)
            pred = model(img_batch)
            loss = tf.keras.losses.binary_crossentropy(lbl_batch, pred)
        grad = tape.gradient(loss, img_batch)
        adv = img_batch + 0.01 * tf.sign(grad)
        adv = tf.clip_by_value(adv, -1.0, 1.0)
        adv_images.append(adv.numpy())
    return np.concatenate(adv_images, axis=0)

NUM_SAMPLES = 10
X_test_small = X_test[:NUM_SAMPLES]
y_test_small = y_test[:NUM_SAMPLES]
X_test_adv = fgsm_attack_batch(robust_model, X_test_small, y_test_small, epsilon=0.01, batch_size=1)

# 5. Evaluate on adversarial images
y_pred_adv_proba = robust_model.predict(X_test_adv, batch_size=1).flatten()
y_pred_adv = (y_pred_adv_proba > 0.5).astype(int)
print("Robust model evaluation on FGSM adversarial examples:")
print(classification_report(y_test_small, y_pred_adv))
print("ROC-AUC:", roc_auc_score(y_test_small, y_pred_adv_proba))

# 6. (Optional) Visualize before/after as before
def visualize_adversarial(original, adversarial, n=5):
    import matplotlib.pyplot as plt
    plt.figure(figsize=(12, 4))
    for i in range(n):
        plt.subplot(2, n, i+1)
        plt.imshow((original[i] + 1) / 2)
        plt.title("Original")
        plt.axis('off')
        plt.subplot(2, n, i+1+n)
        plt.imshow((adversarial[i] + 1) / 2)
        plt.title("Adversarial")
        plt.axis('off')
    plt.show()
visualize_adversarial(X_test_small, X_test_adv, n=min(5, NUM_SAMPLES))
